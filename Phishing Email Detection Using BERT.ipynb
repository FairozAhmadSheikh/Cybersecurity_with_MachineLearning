{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef6ded4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from transformers import InputExample, InputFeatures\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b38a4d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    phishing_emails = [\n",
    "        \"Your account has been compromised. Click here to reset your password immediately.\",\n",
    "        \"You've won a free iPhone! Visit this link to claim your prize.\",\n",
    "        \"Update your billing information to avoid service suspension.\",\n",
    "        \"We noticed a login attempt from an unknown device. Verify your identity now.\",\n",
    "        \"Urgent: Your account will be locked in 24 hours unless you respond.\"\n",
    "    ]\n",
    "     legitimate_emails = [\n",
    "        \"Your order has been shipped and will arrive in 3 days.\",\n",
    "        \"Thank you for your payment. Your subscription is now active.\",\n",
    "        \"Meeting scheduled for Monday at 10 AM.\",\n",
    "        \"Reminder: Project deadline is next Friday.\",\n",
    "        \"Welcome to our service! Let us know if you need any help.\"\n",
    "    ]\n",
    "    texts = phishing_emails * 100 + legitimate_emails * 100\n",
    "    labels = [1]*len(phishing_emails)*100 + [0]*len(legitimate_emails)*100\n",
    "\n",
    "    return pd.DataFrame({'text': texts, 'label': labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3eb5fd6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fc868e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def convert_to_examples(df):\n",
    "    return df.apply(lambda x: InputExample(guid=None,\n",
    "                                           text_a=x['text'],\n",
    "                                           text_b=None,\n",
    "                                           label=x['label']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dfafaf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def convert_examples_to_tf_dataset(examples, tokenizer, max_length=64):\n",
    "    features = []\n",
    "    for e in examples:\n",
    "        inputs = tokenizer.encode_plus(\n",
    "            e.text_a,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_length,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=False\n",
    "        )\n",
    "        features.append(\n",
    "            InputFeatures(\n",
    "                input_ids=inputs['input_ids'],\n",
    "                attention_mask=inputs['attention_mask'],\n",
    "                label=e.label\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def gen():\n",
    "        for f in features:\n",
    "            yield ({\n",
    "                'input_ids': f.input_ids,\n",
    "                'attention_mask': f.attention_mask\n",
    "            }, f.label)\n",
    "\n",
    "    return tf.data.Dataset.from_generator(\n",
    "        gen,\n",
    "        ({'input_ids': tf.int32, 'attention_mask': tf.int32}, tf.int64),\n",
    "        ({'input_ids': tf.TensorShape([None]),\n",
    "          'attention_mask': tf.TensorShape([None])}, tf.TensorShape([]))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d952ee6b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(df):\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    examples = convert_to_examples(df)\n",
    "    train_examples, test_examples = train_test_split(examples, test_size=0.2, random_state=42)\n",
    "\n",
    "    train_data = convert_examples_to_tf_dataset(train_examples, tokenizer)\n",
    "    test_data = convert_examples_to_tf_dataset(test_examples, tokenizer)\n",
    "    train_data = train_data.shuffle(100).batch(16).prefetch(tf.data.AUTOTUNE)\n",
    "    test_data = test_data.batch(16).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(train_data, epochs=3, validation_data=test_data)\n",
    "\n",
    "    preds = model.predict(test_data).logits\n",
    "    y_pred = tf.argmax(preds, axis=1).numpy()\n",
    "    y_true = [y for _, y in test_data.unbatch()]\n",
    "\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
